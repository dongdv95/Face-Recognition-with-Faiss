{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOTDATA = 'dataset'\n",
    "\n",
    "def read_file(path):\n",
    "    img_path = []\n",
    "    for paths, subdirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            img_path.append(os.path.join(paths,name))\n",
    "    return img_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset\\\\Eimi_Fukada\\\\1.jpg',\n",
       " 'dataset\\\\Eimi_Fukada\\\\2.jpg',\n",
       " 'dataset\\\\Eimi_Fukada\\\\3.jpg',\n",
       " 'dataset\\\\Eimi_Fukada\\\\4.jpg',\n",
       " 'dataset\\\\Eimi_Fukada\\\\5.jpg',\n",
       " 'dataset\\\\Eimi_Fukada\\\\6.jpg',\n",
       " 'dataset\\\\Riho_Fujimori\\\\1.jpg',\n",
       " 'dataset\\\\Riho_Fujimori\\\\2.jpg',\n",
       " 'dataset\\\\Riho_Fujimori\\\\3.jpg',\n",
       " 'dataset\\\\Riho_Fujimori\\\\4.jpg',\n",
       " 'dataset\\\\Riho_Fujimori\\\\5.jpg',\n",
       " 'dataset\\\\Riho_Fujimori\\\\6.jpg',\n",
       " 'dataset\\\\Yua_Mikami\\\\1.jpg',\n",
       " 'dataset\\\\Yua_Mikami\\\\2.jpg',\n",
       " 'dataset\\\\Yua_Mikami\\\\3.jpg',\n",
       " 'dataset\\\\Yua_Mikami\\\\4.jpg',\n",
       " 'dataset\\\\Yua_Mikami\\\\5.jpg',\n",
       " 'dataset\\\\Yua_Mikami\\\\6.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs = read_file(ROOTDATA)\n",
    "train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceEncode = []\n",
    "img_paths = []\n",
    "for path in train_imgs:\n",
    "    # read img\n",
    "    img = face_recognition.load_image_file(path)\n",
    "    # detect face\n",
    "    img_location = face_recognition.face_locations(img)\n",
    "    if len(img_location) > 0:\n",
    "        #crop face\n",
    "        for (top,right,bottom,left) in img_location:\n",
    "            face_img = img[top:bottom,left:right]\n",
    "            # save face img\n",
    "            pil_img = Image.fromarray(face_img)\n",
    "            pil_img.save(path)\n",
    "            # encode\n",
    "            face_encode = face_recognition.face_encodings(img)[0]\n",
    "            faceEncode.append(face_encode)\n",
    "            img_paths.append(path)\n",
    "len(faceEncode)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.array([img.split('\\\\')[-2] for img in img_paths])\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceEncode = np.array(faceEncode,dtype=np.float32)\n",
    "faceEncode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index with faiss\n",
    "face_index = faiss.IndexFlatL2(128)\n",
    "# add vector\n",
    "face_index.add(faceEncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "test_img = face_recognition.load_image_file('test/fukada.jpg')\n",
    "img_location = face_recognition.face_locations(test_img)\n",
    "if len(img_location) > 0:\n",
    "    #crop face\n",
    "    for (top,right,bottom,left) in img_location:\n",
    "        face_img = img[top:bottom,left:right]\n",
    "        qr = face_recognition.face_encodings(face_img)[0]\n",
    "qr.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to (n,128)\n",
    "qr = np.array(qr,dtype=np.float32).reshape(-1,128)\n",
    "qr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 12, 14, 13, 10]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,result = face_index.search(qr, k=5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Eimi_Fukada', 'Eimi_Fukada', 'Eimi_Fukada', 'Riho_Fujimori',\n",
       "       'Riho_Fujimori', 'Yua_Mikami', 'Yua_Mikami', 'Yua_Mikami'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = [train_labels[i] for i in result[0]]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save index\n",
    "faiss.write_index(face_index,'face_index.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('labels.npy', train_labels) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da02f3fccd87cb32942c311f4f3b948ad625fc48063dc2861a91e752e80f65b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
